
# Large Language Models

This project highlights some of the most advanced large language models (LLMs) and their corresponding end-user applications. 

### Some important Frontier models and their end-user:

1- OpenAI
Models: GPT, O1
Chat: ChatGPT

2- Anthropic
Models: Claude
Chat: Claude

3- Google
Models: Gemini
Chat: Gemini Advance

3- Cohere
Models: Command R+
Chat: Command R+

4- Meta
Models: Llama
Chat: meta.ai

5- Perplexity
Models: Perplexity
Search: Perplexity

## Building AI Agent Framework

### Agentic AI: Smarter Problem-Solving

Agentic AI helps AI agents tackle problems efficiently. Here's how:

- **Break tasks into steps** → Different AI models handle different parts.
- **Use tools** → AI can access extra tools for better results.
- **Collaborate** → AI agents work together in an environment.
- **Plan ahead** → One AI organizes tasks for the others.
- **Think independently** → AI remembers and acts beyond simple replies.

## Comparing LLMs to select for a project

Compare the following features of an LLM.

1- Basics 1:

- **Open-source or closed**
- **Release date and knowledge cut-off**
- **Parameters**
- **Training tokens**
- **Context length**

2- Basics 2:

- **Inference cost** -> API charge, Subscription or Runtime compute
- **Training cost**
- **Build cost** -> How much work will it be for you to create this solution.
- **Time to Market** -> How long does it take to build the LLM
- **Rate limits** -> run into some limits on how frequently you can call them. This is typically the case for subscription plans.
- **Speed** -> How quickly can generate a whole response?
- **Latency** -> How quickly does it first start responding with each token?
- **License** -> Whether we are dealing with open source or closed source to be allowed to use it.

3- The Chincilla Scaling Law:

The number of parameters is roughly proportional to the size of our training data to the number of training tokens. \
Let's say it's an 8 billion parameter model, and we get to the point where we start to see that we're getting diminishing returns. Adding in more training data isn't significantly affecting the model.

How many more parameters do I need given extra training data? \
Answer: if we were then to double the amount of training data from that that point of diminishing returns, we would need double the number of weights you'd need to go from 8 billion to 16 billion parameters to be able to consume twice the training data and learn from it in an effective way.

How much more training data am I going to need to be able to to take advantage of that? \
Answer is: we would you would roughly need to double the size of our training data set.

## Reference

